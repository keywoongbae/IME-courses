## 02. Dynamic Programming Algorithm

### Algorithmic Design Paradigm

- **Greedy Algorithm**
  - 미래를 생각하지 않고 각 단계에서 최선의 선택을 하는 기법.
  - 각 단계에서 제약조건들을 최적화함으로써 점진적으로 솔루션을 구축.
- **Divide-and-conquer**
  - 문제를 재귀적으로 개별 하위 문제로 분해하고, 각 하위 문제를 독립적으로 해결하며, 하위 문제에 대한 해결책을 결합하여 원래 문제에 대한 해결책을 형성하는 것(하위 문제는 다소 독립적임)
  - 대표적으로 분기한정법이 있다.
- **Dynamic Programming (기억하면서 풀기)**
  - 문제를 일련의 중복된 하위 문제로 분해하고, 점점 더 큰 하위 문제에 대한 해결책을 구축.
  - 마지막 단계부터 거꾸로 작업하여 해결할 수 있는 하위 문제로 분해하는 것.
  - 위의 두 알고리즘들은 DP보다 더 효율적이나, DP는 적용가능 범위가 넓으며, 최적의 해결책으로 이어짐.



### DP Algorithm

- 명제
  - 모든 초기 상태 $s_1$에 대해, 최적의 cost-to-go 함수 $V^*_1(s_1)$은 기간 $N-1$에서 $1$로 역진하는 다음 알고리즘의 마지막 단계에 의해 주어진 $V_1(s_1)$과 같음.
  - $V_N(s_N)=g_N(s_N)$
  - $V_t(s_t) = \underset{a_t \in A_s}{\min} [g_t(s_t, a_t) + V_{t+1}(f_t(s_t, a_t))], \ \forall t = \{1, .., N-1\}$
  - 만약 $a^*_t = d^*_t(s_t)가 $
- 명제 증명
  - For any admissible policy $\pi = (d_1, d_2,...,d_{N-1})$ and its truncated policy $\pi^t = (d_t, d_{t+1}, ..., d_{N-1}), \ \forall t = \{1,.., N-1\}$,
  - Let $V^*_t(s_t)$ be the optimal cost-to-go function for the N-t stage problem that starts from a state $s_t$.
  - $V^*_t(s_t) = \underset{\pi^t}{\min} \{g_N(s_N)+\Sigma_{i=t}^{N-1} g_i(s_i, a_i) \}$
  - For $t=N$, $V^*_N(s_N) = g_N(s_N)$, $V^*_t(s_t) = V_t(s_t)$, generated by Bellman Eq. for $\forall t \in \{1,.., N-1 \}$, $ V^*_1(s_1) = V_1(s_1)$
  - Assume that for t and all $s_{t+1}$, we have $V^*_{t+1}(s_{t+1}) = V_{t+1}(s_{t+1})$
  - Then since $\pi^t = (d_t, \pi^{t+1}), \forall s_t$
  - $V^*_t(s_t) = \underset{(d_t, \pi^{t+1})}{\min} \{g_N(s_N) + g_t(s_t, a_t) + \Sigma_{i = t+1}^{N-1}g_i(s_i, a_i) \}$
    $= \underset{d_t}{\min} [g_t(s_t,a_t) + \underset{\pi^{t+1}}{\min}\{g_n(s_n)+ \Sigma^{N-1}_{i=t+1} g_i(s_i,a_i) \} ]$
    $= \underset{d_t}{\min} [g_t(s_t,a_t) + V_{t+1}(f_t(s_t, a_t))]$
    $= \underset{a_t \in A_s}{\min}[g(s_t,a_t) + V_{t+1}(f_t(s_t, a_t))]$
    $= V_t(s_t)$
  - $\therefore V^*_1(s_1) = V_1(s_1)$



### DP 알고리즘의 목적

- **개요**

  - DP는 하나의 큰 문제를 여러 개의 작은 문제로 나누어서 그 결과를 저장하여 다시 큰 문제를 해결할 때 사용하는 알고리즘.

- **DP를 쓰는 이유**

  - 일반적인 재귀를 단순히 사용 시 동일한 작은 문제들이 여러 번 반복되는 현상을 방지하기 위해서.

- **DP의 사용조건**

  - DP가 적용되기 위해서는 2가지 조건 (1) Overlapping subproblems (2) Optimal substructure를 만족해야 한다.
  - (1) Overlapping subproblems (겹치는 부분 문제)
    - 동일한 작은 문제들이 반복하여 나타나는 경우에 사용이 가능
    - ![image-20230915152726910](.\img\image-20230915152726910.png)
    - 위 경우는 피보나치 수열을 트리 형태로 분해한 결과. 소문제가 상위 문제를 해결하기 위해 사용되는 것을 볼 수 있음.
    - 이처럼,  **각각의 소문제가 상위문제의 결과를 찾는데 중복되어 자원이 낭비되는 경우에 Dynamic Programming 적용!**
  - (2) Optimal substructure (최적 부분 구조)
    - 부분 문제의 최적 결과 값을 사용해 전체 문제의 최적 결과를 낼 수 있는 경우.
    - ![image-20230915153107588](.\img\image-20230915153107588.png)
    - $A \rightarrow X$에서 최단 경로는 AX2,  $X \rightarrow B$에서 최단 경로는 BX2. $A \rightarrow B$에서 최단 경로는 AX2+BX2임.
    - 이처럼, **부분문제에서 구한 최적 결과가 전체 문제에서도 동일하게 적용되어 결과가 변하지 않을 때 Dynamic Programming 적용!**

- **DP의 방법**

  - (1) 메모리제이션 (하향식)

    - 하위 문제에 대한 정답을 계산했는지 확인해가며 문제를 자연스러운 방식으로 풀어나가는 방법.

    - 이전 계산값을 메모리에 저장하여 메모리 공간을 약간 더 사용함.

    - 매번 다시 실행하지 않도록 하여 실행속도를 빠르게 한다.

    - ```python
      dp = [0]*100 # 소문제 결과들을 저장할 리스트
      dp[0] = 1
      dp[1] = 1
      
      def fibonacci(n):
          if dp[n]==0: # 만약 계산한 적이 없다면,
              dp[n] = fibonacci(n-1) + fibonacci(n-2)
              
          return dp[n]
          
      print(fibonacci(10))
      
      """
      89
      """
      ```

  - (2) 타뷸레이션 (상향식)

    - 상향식은 더 작은 하위 문제부터 살펴본 다음, 작은 문제의 정답을 이용해서 큰 문제의 정답을 풀어나가는 방법.

    - ```python
      def fibonacci(n):
          dp = [0] * (n+1)
          dp[0] = 1
          dp[1] =1
          
          # 작은값(소문제)부터 직접 계산하면서 진행
          for i in range(2, n+1):
              dp[i] = dp[i-1] + dp[i-2]
          return dp[n]
          
      print(fibonacci(10))
      
      """
      89
      """
      ```

  - 재귀와 DP의 차이

    - 재귀함수 코드는 다음과 같다.

      - ```python
        def fib(n):
            if n == 0:
                return 0
            elif n == 1 or n == 2:
                return 1
            else:
                return fib(n - 1) + fib(n - 2)
        ```

    - 재귀는 자기 자신을 호출하며, **n이 더이상 쪼개지지 않을 때까지 쪼갠다**. (쪼개는 것이 핵심)

    - 반면, DP는 **이전의 계산한 값들을 저장함으로써** 동일한 계산의 반복 수행을 제거한다. (저장하는 것이 핵심)

- DP 알고리즘의 특징

  - 문제가 단계로 나뉘어져 있다.
  - 각각의 단계는 그 단계와 관련있는 
  - 각 state는 action을 요구한다.
  - 어떤 단계에서의 action은 다음 단계의 또다른 state로 변환된다.
  - 잘 정의된 state
  - 각 stage에서, 각 state에서의 최적의 결정은 인접한 state와 decision에 의존하지 않는다.
  - recursive relationship이 존재한다.